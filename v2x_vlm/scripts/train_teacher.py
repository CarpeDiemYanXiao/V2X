# scripts/train_teacher.py
import os
import sys
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from tqdm import tqdm
import logging
from PIL import Image
import numpy as np
from torch.optim.lr_scheduler import LambdaLR

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
sys.path.insert(0, ROOT)
# ç¡®ä¿èƒ½æ‰¾åˆ° Florence-2 çš„è·¯å¾„ (æ ¹æ®ä½ çš„ç¯å¢ƒè°ƒæ•´)
sys.path.append("/root/autodl-tmp/models/florence2/Florence-2-base")
sys.path.append("/root/autodl-tmp/models/florence2/Florence-2-large")

from src.utils.config import load_config
from src.data.dataset import V2XVLMDataset
from src.models.v2x_vlm_teacher import V2XVLMTeacher
from src.models.losses import trajectory_loss
from src.utils.tokenizer import TrajectoryTokenizer

def collate_fn(batch):
    """æ‹¼æ¥è½¦è¾†-åŸºç¡€è®¾æ–½å›¾åƒ"""
    vehicle_imgs = [b["vehicle_img"] for b in batch]
    infra_imgs = [b["infra_img"] for b in batch]
    prompts = [b["prompt"] for b in batch]
    trajectories = torch.stack([b["trajectory"] for b in batch])

    combined_images = []
    for v_img, i_img, prompt in zip(vehicle_imgs, infra_imgs, prompts):
        if not prompt.strip():
            raise ValueError(f"Empty prompt found: {prompt}")
        
        # è®© processor å¤„ç†æˆªæ–­ï¼Œè¿™é‡Œä¸æ‰‹åŠ¨æˆªæ–­
        # prompt = prompt[:512] 
        
        # ç¡®ä¿å°ºå¯¸ä¸€è‡´
        if v_img.size != i_img.size:
            i_img = i_img.resize(v_img.size)
        
        # æ°´å¹³æ‹¼æ¥å›¾åƒ [Iv, Ii]
        combined_width = v_img.width + i_img.width
        combined_img = Image.new('RGB', (combined_width, v_img.height))
        combined_img.paste(v_img, (0, 0))
        combined_img.paste(i_img, (v_img.width, 0))
        
        combined_images.append(combined_img)

    return {
        "combined_images": combined_images,
        "prompts": prompts,
        "trajectory": trajectories
    }

def setup_logger():
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - [TeacherTrain] - %(message)s'
    )
    return logging.getLogger(__name__)

def main():
    # 1. åŠ è½½é…ç½®
    cfg_path = os.path.join(ROOT, "configs", "config.yaml")
    cfg = load_config(cfg_path)
    logger = setup_logger()
    
    # ä¿®æ”¹è¾“å‡ºç›®å½•
    original_output_dir = cfg.output_dir
    cfg.output_dir = os.path.join(original_output_dir, "teacher_training")
    os.makedirs(cfg.output_dir, exist_ok=True)
    
    device = torch.device(cfg.device if torch.cuda.is_available() else "cpu")
    logger.info(f"è®­ç»ƒ Teacher æ¨¡å‹ | è®¾å¤‡: {device} | è¾“å‡º: {cfg.output_dir}")

    # [æ ¸å¿ƒ] åˆå§‹åŒ– Tokenizer
    tokenizer = TrajectoryTokenizer(cfg)

    # 2. æ•°æ®å‡†å¤‡
    train_dataset = V2XVLMDataset(split="train", cfg=cfg)
    train_loader = DataLoader(
        train_dataset,
        batch_size=cfg.batch_size,
        shuffle=True,
        num_workers=cfg.num_workers,
        collate_fn=collate_fn,
        pin_memory=True,
        drop_last=True
    )

    val_dataset = V2XVLMDataset(split="val", cfg=cfg)
    val_loader = DataLoader(
        val_dataset,
        batch_size=cfg.batch_size,
        shuffle=False,
        num_workers=cfg.num_workers,
        collate_fn=collate_fn,
        pin_memory=True
    )

    # 3. åˆå§‹åŒ– Teacher æ¨¡å‹
    logger.info("åˆå§‹åŒ– Teacher æ¨¡å‹ (Florence-2-large)...")
    teacher = V2XVLMTeacher(cfg).to(device)

    # 4. é…ç½®å‚æ•°å†»ç»“ç­–ç•¥
    # å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡æˆ–é…ç½®é€‰æ‹©è®­ç»ƒç­–ç•¥
    freeze_backbone = os.getenv("FREEZE_BACKBONE", "false").lower() == "true"
    
    head_params = []
    backbone_params = []

    for name, param in teacher.named_parameters():
        # A. è§†è§‰éƒ¨åˆ†ï¼šæ°¸è¿œå†»ç»“
        if "vision" in name.lower() or "davit" in name.lower():
            param.requires_grad = False
            
        # B. é¢„æµ‹å¤´ (Head)ï¼šå¿…é¡»è®­ç»ƒ
        elif "traj_head" in name or "feature_fusion" in name:
            param.requires_grad = True
            head_params.append(param)
            
        # C. è¯­è¨€æ¨¡å‹ (Backbone)ï¼šæ ¹æ®ç­–ç•¥å†³å®š
        else:
            if freeze_backbone:
                # å®Œå…¨å†»ç»“æ¨¡å¼ï¼šåªè®­ç»ƒé¢„æµ‹å¤´
                param.requires_grad = False
            else:
                # å¾®è°ƒæ¨¡å¼ï¼šè§£å†»backboneï¼Œä½†ç”¨å°å­¦ä¹ ç‡
                param.requires_grad = True
                backbone_params.append(param)
    
    if freeze_backbone:
        logger.info("ğŸ”¥ ç­–ç•¥: å®Œå…¨å†»ç»“Backbone | åªè®­ç»ƒé¢„æµ‹å¤´")
    else:
        logger.info("ğŸ”¥ ç­–ç•¥: è§†è§‰å†»ç»“ | Backboneå¾®è°ƒ(2e-5) | Headå¿«è®­(1e-3)")

    trainable_params = sum(p.numel() for p in teacher.parameters() if p.requires_grad)
    logger.info(f"Teacher å¯è®­ç»ƒå‚æ•°é‡: {trainable_params/1e6:.2f}M")
    # é¢„æœŸï¼šå‚æ•°é‡åº”è¯¥å¤§å¹…å‡å°‘ï¼Œåªå‰©å‡ ç™¾ä¸‡æˆ–è€…å‡ åƒä¸‡

    # è°ƒæ•´å­¦ä¹ ç‡ï¼šæ ¹æ®è®­ç»ƒç­–ç•¥é€‰æ‹©
    if freeze_backbone:
        # å®Œå…¨å†»ç»“æ¨¡å¼ï¼šåªä¼˜åŒ–é¢„æµ‹å¤´ï¼Œä½¿ç”¨è¾ƒå¤§å­¦ä¹ ç‡
        optimizer = torch.optim.AdamW(
            head_params,
            lr=1e-3,
            weight_decay=0.01
        )
        # ç®€å•çš„cosineè°ƒåº¦å™¨
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            optimizer,
            T_max=cfg.epochs,
            eta_min=1e-5
        )
    else:
        # å¾®è°ƒæ¨¡å¼ï¼šåˆ†åˆ«è®¾ç½®backboneå’Œheadçš„å­¦ä¹ ç‡
        optimizer = torch.optim.AdamW([
            {'params': backbone_params, 'lr': 2e-5},
            {'params': head_params, 'lr': 1e-3}
        ], weight_decay=0.01)
        
        # ä½¿ç”¨warmup + cosineè°ƒåº¦å™¨
        num_actual_updates_per_epoch = len(train_loader) // accumulation_steps
        num_warmup_updates = min(10, num_actual_updates_per_epoch // 10)
        num_training_updates = num_actual_updates_per_epoch * cfg.epochs
        
        def lr_lambda(step):
            if step < num_warmup_updates:
                warmup_start = 0.1
                warmup_end = 1.0
                if num_warmup_updates > 0:
                    return warmup_start + (warmup_end - warmup_start) * (step + 1) / num_warmup_updates
                else:
                    return 1.0
            else:
                progress = (step - num_warmup_updates) / max(1, (num_training_updates - num_warmup_updates))
                return max(0.1, 0.5 * (1 + np.cos(np.pi * progress)))
        
        from torch.optim.lr_scheduler import LambdaLR
        scheduler = LambdaLR(optimizer, lr_lambda)

    # [æ ¸å¿ƒ] æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ï¼ˆåªåœ¨å¾®è°ƒæ¨¡å¼ä¸‹ä½¿ç”¨ï¼‰
    accumulation_steps = 8 if not freeze_backbone else 1
    
    best_val_l2 = float('inf')

    # 6. è®­ç»ƒå¾ªç¯
    for epoch in range(cfg.epochs):
        logger.info(f"Epoch {epoch + 1}/{cfg.epochs}")
        teacher.train()
        epoch_loss = 0.0
        
        optimizer.zero_grad()

        for batch_idx, batch in enumerate(tqdm(train_loader, desc="Training")):
            combined_images = batch["combined_images"]
            prompts = batch["prompts"]
            
            gt_traj_coords = batch["trajectory"].to(device)
            gt_tokens = tokenizer.coords_to_tokens(gt_traj_coords).to(device)
            
            # ã€å…³é”®ä¿®æ”¹ã€‘å¿…é¡»åŠ ä¸Šè¿™è¡Œï¼æŠŠ 0 (Padding/æ— æ•ˆä½) å˜æˆ -100ï¼Œé˜²æ­¢æ¨¡å‹å·æ‡’å­¦ 0
            gt_tokens[gt_tokens == 0] = -100 
            gt_tokens[gt_tokens == 1023] = -100

            outputs = teacher(combined_images, prompts)
            traj_logits = outputs["trajectory_logits"]
            
            # è®¡ç®—åˆ†ç±» Lossï¼Œä½¿ç”¨è¾ƒå°çš„label smoothingï¼ˆ0.05ï¼‰æé«˜è®­ç»ƒç¨³å®šæ€§
            loss = trajectory_loss(traj_logits, gt_tokens, label_smoothing=0.05)

            # [æ ¸å¿ƒ] æ¢¯åº¦ç´¯ç§¯
            loss = loss / accumulation_steps
            loss.backward()

            # æ¢¯åº¦ç´¯ç§¯ï¼ˆåªåœ¨å¾®è°ƒæ¨¡å¼ä¸‹ï¼‰
            if freeze_backbone:
                # å®Œå…¨å†»ç»“æ¨¡å¼ï¼šæ¯ä¸ªbatchéƒ½æ›´æ–°
                optimizer.zero_grad()
                loss.backward()
                torch.nn.utils.clip_grad_norm_(head_params, max_norm=1.0)
                optimizer.step()
            else:
                # å¾®è°ƒæ¨¡å¼ï¼šä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
                loss = loss / accumulation_steps
                loss.backward()
                
                if (batch_idx + 1) % accumulation_steps == 0:
                    torch.nn.utils.clip_grad_norm_(teacher.parameters(), max_norm=1.0)
                    optimizer.step()
                    scheduler.step()
                    optimizer.zero_grad()
            
            if freeze_backbone:
                epoch_loss += loss.item()
            else:
                epoch_loss += loss.item() * accumulation_steps
            
            # Debug æ‰“å° (åªåœ¨æ¯ä¸ª epoch çš„ç¬¬ä¸€ä¸ª batch æ‰“å°)
            if batch_idx == 0:
                last_step_idx = 44 
                reshaped_logits = traj_logits.view(-1, 45, 2, 1024)
                pred_probs = torch.softmax(reshaped_logits[0, last_step_idx, 0], dim=-1)
                max_prob, max_idx = torch.max(pred_probs, dim=-1)
                
                # å¯¹åº”çš„çœŸå€¼
                gt_val = gt_tokens[0, last_step_idx, 0].item()
                
                # è®¡ç®—top-5é¢„æµ‹
                top5_probs, top5_indices = torch.topk(pred_probs, k=5)
                
                # ä¿®æ­£æ‰“å°é€»è¾‘ï¼šå¦‚æœçœŸå€¼æ˜¯ -100ï¼Œè¯´æ˜è¿™æ­¥æ˜¯æ— æ•ˆä½
                gt_display = "PADDING" if gt_val == -100 else gt_val
                # æ˜¾ç¤ºä¸¤ä¸ªå‚æ•°ç»„çš„å­¦ä¹ ç‡
                backbone_lr = optimizer.param_groups[0]['lr']
                head_lr = optimizer.param_groups[1]['lr']
                # è·å–å½“å‰è°ƒåº¦å™¨æ­¥æ•°
                current_scheduler_step = scheduler.last_epoch if hasattr(scheduler, 'last_epoch') else 0
                print(f"\n[Debug T=4.5s X-axis] GT Token: {gt_display} | Pred Max: {max_idx.item()} (Prob: {max_prob.item():.4f})")
                print(f"[Debug LR] Backbone: {backbone_lr:.2e} | Head: {head_lr:.2e} | Scheduler Step: {current_scheduler_step}")
                print(f"[Debug Top-5] {[(idx.item(), prob.item()) for idx, prob in zip(top5_indices, top5_probs)]}")
        avg_loss = epoch_loss / len(train_loader)
        if freeze_backbone:
            current_lr = optimizer.param_groups[0]['lr']
            logger.info(f"Train Loss: {avg_loss:.4f} | LR: {current_lr:.2e}")
            scheduler.step()  # åœ¨epochç»“æŸæ—¶æ›´æ–°
        else:
            backbone_lr = optimizer.param_groups[0]['lr']
            head_lr = optimizer.param_groups[1]['lr']
            logger.info(f"Train Loss: {avg_loss:.4f} | LR Backbone: {backbone_lr:.2e} | LR Head: {head_lr:.2e}")

        # éªŒè¯ (ç›‘æ§ L2 è¯¯å·®)
        val_l2 = validate(teacher, val_loader, device, tokenizer)
        logger.info(f"Val L2 Error: {val_l2:.4f} meters")

        # ä¿å­˜æœ€ä½³æ¨¡å‹ (æ ¹æ® L2 è¯¯å·®)
        if val_l2 < best_val_l2:
            best_val_l2 = val_l2
            save_path = os.path.join(cfg.output_dir, "teacher_best.pth")
            torch.save(teacher.state_dict(), save_path)
            logger.info(f"ä¿å­˜æœ€ä½³æ¨¡å‹è‡³: {save_path}")

@torch.no_grad()
def validate(model, loader, device, tokenizer):
    model.eval()
    total_l2_error = 0.0
    total_valid_points = 0  # ç»Ÿè®¡æœ‰æ•ˆç‚¹æ•°
    
    pbar = tqdm(loader, desc="Validating")
    
    for batch in pbar:
        combined_images = batch["combined_images"]
        prompts = batch["prompts"]
        
        gt_traj_coords = batch["trajectory"].to(device)
        gt_tokens = tokenizer.coords_to_tokens(gt_traj_coords).to(device)
        # éªŒè¯é›†ä¹Ÿè¦å¤„ç† Paddingï¼Œä»¥ä¾¿ç”Ÿæˆ Mask
        gt_tokens[gt_tokens == 0] = -100

        outputs = model(combined_images, prompts)
        traj_logits = outputs["trajectory_logits"]

        # 1. é¢„æµ‹ Token
        pred_token_ids = torch.argmax(traj_logits, dim=-1).view(-1, 45, 2)
        
        # 2. è½¬å›åæ ‡
        pred_coords = tokenizer.tokens_to_coords(pred_token_ids)
        
        # 3. åˆ›å»º Maskï¼šåªè®¡ç®—ä¸æ˜¯ -100 çš„ç‚¹
        # åªè¦ (x, y) ä¸­æœ‰ä¸€ä¸ªæ˜¯ -100ï¼Œè¿™ä¸ªç‚¹å°±æ˜¯æ— æ•ˆçš„
        mask = (gt_tokens != -100).all(dim=-1) # [B, 45]
        
        # 4. è®¡ç®—è·ç¦»
        distances = torch.norm(pred_coords - gt_traj_coords, dim=-1)
        valid_distances = distances[mask] # åªå–æœ‰æ•ˆè·ç¦»
        
        if valid_distances.numel() > 0:
            total_l2_error += valid_distances.sum().item()
            total_valid_points += valid_distances.numel()
            
            pbar.set_postfix({"L2": f"{valid_distances.mean().item():.2f}m"})
        
    avg_l2 = total_l2_error / total_valid_points if total_valid_points > 0 else 0.0
    return avg_l2



if __name__ == "__main__":
    main()